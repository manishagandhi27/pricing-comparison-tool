UzKBtCqMiARY8JMGTKR45QmylzCyU421jqe4VewN



from langchain.document_loaders import DoclingLoader
from langchain.embeddings import HuggingFaceEmbeddings
from elasticsearch import Elasticsearch, helpers
import cohere

# Initialize ES, embeddings, and Cohere
es = Elasticsearch(["http://localhost:9200"])
index_name = "my_chunks_index"
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
co = cohere.Client(api_key="your_cohere_trial_key_here")  # Replace with your trial key

# Create index (unchanged)
if not es.indices.exists(index=index_name):
    es.indices.create(index=index_name, body={
        "mappings": {
            "properties": {
                "content": {"type": "text", "copy_to": "semantic_content"},
                "semantic_content": {"type": "semantic_text", "inference_id": "elser_inference"},
                "dense_embedding": {"type": "dense_vector", "dims": 384, "index": true, "similarity": "cosine"},
                "metadata": {"type": "object", "dynamic": true},
                "tags": {"type": "keyword"},
                "file_description": {"type": "text"},
                "file_name": {"type": "keyword"}
            }
        }
    })
    print(f"Index {index_name} created!")

# Bulk index chunks (debugging version)
loader = DoclingLoader(file_path="report.pdf")  # Adjust path
chunks = loader.load()
bulk_actions = []
for i, chunk in enumerate(chunks):
    try:
        meta = chunk.metadata if isinstance(chunk.metadata, dict) else {"source": str(chunk.metadata) if chunk.metadata else ""}
        embedding = embeddings.embed_query(chunk.page_content)
        if not isinstance(embedding, list) or len(embedding) != 384:
            raise ValueError(f"Invalid embedding for chunk {i}: {embedding}")
        action = {
            "_op_type": "index",
            "_index": index_name,
            "_id": str(i),
            "_source": {
                "content": chunk.page_content,
                "dense_embedding": embedding,
                "metadata": meta,
                "tags": ["AI", "tech"],
                "file_description": "AI trends report",
                "file_name": "unknown.pdf"
            }
        }
        bulk_actions.append(action)
    except Exception as e:
        print(f"Error preparing chunk {i}: {str(e)}")
        continue

success, failed = helpers.bulk(es, bulk_actions, chunk_size=1000, raise_on_error=False)
print(f"Successfully indexed {success} chunks in bulk!")
if failed:
    print(f"Failed to index {len(failed)} chunks:")
    for fail in failed:
        print(f"Failed doc ID: {fail.get('index', {}).get('_id', 'unknown')}, Error: {fail.get('index', {}).get('error', 'unknown')}")

# Hybrid search with Cohere reranking
def hybrid_search_with_cohere_reranking(query, top_k=5, rerank_candidates=10):
    query_embedding = embeddings.embed_query(query)
    hybrid_query = {
        "size": rerank_candidates,
        "retriever": {
            "rrf": {
                "retrievers": [
                    {"standard": {"query": {"match": {"content": query}}}},
                    {"standard": {"query": {"semantic": {"field": "semantic_content", "query": query}}}},
                    {"knn": {"field": "dense_embedding", "query_vector": query_embedding, "k": rerank_candidates, "num_candidates": 100}}
                ]
            }
        }
    }

    # Initial retrieval
    response = es.search(index=index_name, body=hybrid_query)
    rrf_results = response["hits"]["hits"]
    docs = [hit["_source"]["content"] for hit in rrf_results]

    # Cohere reranking
    rerank_response = co.rerank(query=query, documents=docs, model="rerank-english-v3.0", top_n=top_k)
    reranked_results = [rrf_results[r.index] for r in rerank_response.results]

    # Format results
    results = []
    for hit, rerank_result in zip(reranked_results, rerank_response.results):
        meta = hit["_source"].get("metadata", {})
        result = {
            "score": f"{hit['_score']:.4f} (reranked: {rerank_result.relevance_score:.4f})",
            "content": hit["_source"]["content"],
            "tags": hit["_source"].get("tags", []),
            "file_name": hit["_source"].get("file_name", "unknown"),
            "file_description": hit["_source"].get("file_description", ""),
            "page": meta.get("dl_items", {}).get("page", "N/A") if "dl_items" in meta else "N/A",
            "source": meta.get("source", "N/A")
        }
        results.append(result)

    print(f"\nHybrid Search with Cohere Reranking for '{query}' (Top {top_k}):")
    for i, res in enumerate(results, 1):
        print(f"{i}. Score: {res['score']}")
        print(f"   Content: {res['content']}")
        print(f"   Tags: {', '.join(res['tags']) or 'None'}")
        print(f"   File: {res['file_name']}")
        print(f"   Description: {res['file_description']}")
        print(f"   Page: {res['page']}")
        print(f"   Source: {res['source']}")
        print("---")
    print(f"Total hits: {response['hits']['total']['value']}")

    return results

# Test
query = "AI and machine learning"
results = hybrid_search_with_cohere_reranking(query)
