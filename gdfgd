from langchain.document_loaders import DoclingLoader
from langchain.embeddings import HuggingFaceEmbeddings
from elasticsearch import Elasticsearch, helpers
from sentence_transformers import CrossEncoder  # New import for L-6-v2
import torch

# Initialize ES, embeddings, and L-6-v2 reranker
es = Elasticsearch(["http://localhost:9200"])
index_name = "my_chunks_index"
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
reranker_model_name = "cross-encoder/ms-marco-MiniLM-L-6-v2"
reranker = CrossEncoder(reranker_model_name, max_length=512)  # Simplified initialization
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# Note: CrossEncoder handles device placement internally, but we'll ensure GPU if available
reranker.model.to(device)

# Bulk index (unchanged from your BAAI version)
loader = DoclingLoader(file_path="report.pdf")  # Adjust path
chunks = loader.load()
bulk_actions = []
for i, chunk in enumerate(chunks):
    try:
        meta = chunk.metadata if isinstance(chunk.metadata, dict) else {"source": str(chunk.metadata) if chunk.metadata else ""}
        embedding = embeddings.embed_query(chunk.page_content)
        if not isinstance(embedding, list) or len(embedding) != 384:
            raise ValueError(f"Invalid embedding for chunk {i}: {embedding}")
        action = {
            "_op_type": "index",
            "_index": index_name,
            "_id": str(i),
            "_source": {
                "content": chunk.page_content,
                "dense_embedding": embedding,
                "metadata": meta,
                "tags": ["AI", "tech"],
                "file_description": "AI trends report",
                "file_name": "unknown.pdf"
            }
        }
        bulk_actions.append(action)
    except Exception as e:
        print(f"Error preparing chunk {i}: {str(e)}")
        continue

success, failed = helpers.bulk(es, bulk_actions, chunk_size=1000, raise_on_error=False)
print(f"Successfully indexed {success} chunks in bulk!")
if failed:
    print(f"Failed to index {len(failed)} chunks:")
    for fail in failed:
        print(f"Failed doc ID: {fail.get('index', {}).get('_id', 'unknown')}, Error: {fail.get('index', {}).get('error', 'unknown')}")

# Hybrid search with L-6-v2 reranking
def hybrid_search_with_minilm_reranking(query, top_k=5, rerank_candidates=10):
    query_embedding = embeddings.embed_query(query)
    hybrid_query = {
        "size": rerank_candidates,
        "retriever": {
            "rrf": {
                "retrievers": [
                    {"standard": {"query": {"match": {"content": query}}}},
                    {"standard": {"query": {"semantic": {"field": "semantic_content", "query": query}}}},
                    {"knn": {"field": "dense_embedding", "query_vector": query_embedding, "k": rerank_candidates, "num_candidates": 100}}
                ]
            }
        }
    }

    # Initial retrieval
    response = es.search(index=index_name, body=hybrid_query)
    rrf_results = response["hits"]["hits"]
    docs = [hit["_source"]["content"] for hit in rrf_results]

    # L-6-v2 reranking
    pairs = [(query, doc) for doc in docs]  # Slightly different syntax for CrossEncoder
    scores = reranker.predict(pairs)  # Direct scoring, no tokenization needed
    reranked = sorted(zip(rrf_results, scores), key=lambda x: x[1], reverse=True)[:top_k]

    # Format results
    results = []
    for hit, score in reranked:
        meta = hit["_source"].get("metadata", {})
        result = {
            "score": f"{hit['_score']:.4f} (reranked: {score:.4f})",
            "content": hit["_source"]["content"],
            "tags": hit["_source"].get("tags", []),
            "file_name": hit["_source"].get("file_name", "unknown"),
            "file_description": hit["_source"].get("file_description", ""),
            "page": meta.get("dl_items", {}).get("page", "N/A") if "dl_items" in meta else "N/A",
            "source": meta.get("source", "N/A")
        }
        results.append(result)

    print(f"\nHybrid Search with MiniLM-L6-v2 Reranking for '{query}' (Top {top_k}):")
    for i, res in enumerate(results, 1):
        print(f"{i}. Score: {res['score']}")
        print(f"   Content: {res['content']}")
        print(f"   Tags: {', '.join(res['tags']) or 'None'}")
        print(f"   File: {res['file_name']}")
        print(f"   Description: {res['file_description']}")
        print(f"   Page: {res['page']}")
        print(f"   Source: {res['source']}")
        print("---")
    print(f"Total hits: {response['hits']['total']['value']}")

    return results

# Test
query = "AI and machine learning"
results = hybrid_search_with_minilm_reranking(query)
