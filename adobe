from langchain.embeddings import HuggingFaceEmbeddings
from elasticsearch import Elasticsearch
import numpy as np

# Initialize embeddings
model_name = "sentence-transformers/all-MiniLM-L6-v2"
embeddings = HuggingFaceEmbeddings(
    model_name=model_name,
    model_kwargs={"device": "cpu"},
    encode_kwargs={"normalize_embeddings": True}
)

# Initialize Elasticsearch
es = Elasticsearch(["http://localhost:9200"])
index_name = "my_chunks_index"

# Define a query
query = "AI and machine learning"
print(f"Query: {query}")

# Generate dense embedding for k-NN
query_embedding = embeddings.embed_query(query)
if isinstance(query_embedding, np.ndarray):
    query_embedding = query_embedding.tolist()
print(f"Query embedding length: {len(query_embedding)}, First 5 values: {query_embedding[:5]}")

# Corrected hybrid search query
hybrid_query = {
    "query": {
        "bool": {  # Wrap sub_searches in a bool query if needed for older versions
            "should": [
                {
                    "match": {  # Lexical search
                        "content": {
                            "query": query,
                            "boost": 1.0
                        }
                    }
                },
                {
                    "text_expansion": {  # Sparse vector search
                        "semantic_content": {
                            "model_id": "elser_inference",
                            "model_text": query,
                            "boost": 1.0
                        }
                    }
                }
            ]
        },
        "rank": {  # RRF for sub_searches
            "rrf": {
                "window_size": 50,
                "rank_constant": 20
            }
        }
    },
    "knn": {  # Dense vector search
        "field": "dense_embedding",
        "query_vector": query_embedding,
        "k": 10,
        "num_candidates": 50,
        "boost": 1.0
    }
}

# Execute the search
try:
    response = es.search(index=index_name, body=hybrid_query)
    print("\nSearch Results:")
    for hit in response["hits"]["hits"]:
        score = hit["_score"]
        content = hit["_source"]["content"]
        metadata = hit["_source"].get("metadata", {})
        print(f"Score: {score:.4f}, Content: {content}, Metadata: {metadata}")
    print(f"Total hits: {response['hits']['total']['value']}")
except Exception as e:
    print(f"Error: {str(e)}")
