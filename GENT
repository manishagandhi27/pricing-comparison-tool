from langgraph.graph import StateGraph, END, START
from langgraph.types import Command
from langgraph.prebuilt import create_react_agent
from typing import Literal

# Custom LLM (mocked as a placeholder since I donâ€™t have your model)
class CustomLLM:
    def invoke(self, messages):
        # Simulate your custom LLM response (replace with your actual implementation)
        from langchain_core.messages import AIMessage
        last_msg = messages[-1].content
        if "fetch_code_from_gitlab" in last_msg:
            return AIMessage(content='[fetch_code_from_gitlab(file_location="src/main.py", repo_url="mock/repo")]')
        elif "generate test cases" in last_msg.lower():
            return AIMessage(content="import pytest\ndef test_multiply():\n    assert multiply(2, 3) == 6")
        elif "commit_test_cases" in last_msg:
            return AIMessage(content='[commit_test_cases(test_cases="import pytest...", file_location="src/test_main.py", repo_url="mock/repo", commit_message="Add tests")]')
        elif "review_test_cases" in last_msg:
            return AIMessage(content='[review_test_cases(test_cases="import pytest...", code_content="# Mock code...")]')
        return AIMessage(content="Done")

model = CustomLLM()
tools = [fetch_code_from_gitlab, commit_test_cases, review_test_cases]

# Agent node: LLM orchestrates fetch, generate, commit
def agent_node(state: TestCaseState) -> Command[Literal["supervisor"]]:
    prompt = f"""
    You are a Test Case Generation Agent. Generate and commit test cases for:
    - File: {state['file_location']}
    - Repo: {state['repo_url']}
    
    Tools: fetch_code_from_gitlab, commit_test_cases, review_test_cases (critic uses this).
    
    State:
    - Code: {state.get('code_content', 'Not fetched')}
    - Tests: {state.get('test_cases', 'Not generated')}
    - Critique: {state.get('critique', 'Not reviewed')}
    - Commit: {state.get('commit_status', 'Not committed')}

    Reason step-by-step:
    1. Fetch code if not present.
    2. Generate tests if code fetched but no tests.
    3. If tests critiqued and good, commit them.
    4. If committed, say "Done".
    Use [tool_name(arg1=value1, ...)] syntax for tool calls.
    """
    agent = create_react_agent(model, tools=[fetch_code_from_gitlab, commit_test_cases], prompt=prompt)
    messages = state["messages"]
    response = agent.invoke({"messages": messages})
    messages = response["messages"]

    # Update state based on tool calls or response
    last_msg = messages[-1].content
    if "fetch_code_from_gitlab" in last_msg:
        state["code_content"] = fetch_code_from_gitlab.invoke({"file_location": state["file_location"], "repo_url": state["repo_url"]})
    elif "commit_test_cases" in last_msg and state["test_cases"]:
        state["commit_status"] = commit_test_cases.invoke({
            "test_cases": state["test_cases"],
            "file_location": "src/test_main.py",
            "repo_url": state["repo_url"],
            "commit_message": "Add tests"
        })
    elif state["code_content"] and not state.get("test_cases") and "fetch" not in last_msg.lower():
        state["test_cases"] = last_msg  # Assume LLM generated tests

    return Command(update={"messages": messages}, goto="supervisor")

# Critics node: Reviews test cases
def critics_node(state: TestCaseState) -> Command[Literal["supervisor"]]:
    if not state["test_cases"]:
        return Command(update={"messages": state["messages"] + [HumanMessage("No tests to critique.")]}, goto="supervisor")
    
    prompt = f"""
    You are a Test Case Critic. Review these test cases against the code:
    Code: {state['code_content']}
    Tests: {state['test_cases']}
    Use review_test_cases tool with [review_test_cases(test_cases="{state['test_cases']}", code_content="{state['code_content']}")] syntax.
    """
    critic = create_react_agent(model, tools=[review_test_cases], prompt=prompt)
    messages = state["messages"]
    response = critic.invoke({"messages": messages})
    messages = response["messages"]
    
    last_msg = messages[-1].content
    if "review_test_cases" in last_msg:
        critique = review_test_cases.invoke({"test_cases": state["test_cases"], "code_content": state["code_content"]})
        messages.append(HumanMessage(content=f"Critique: {critique}"))
        state["critique"] = critique
    
    return Command(update={"messages": messages, "critique": state.get("critique")}, goto="supervisor")

# Supervisor node: Controls flow
def supervisor_node(state: TestCaseState) -> Command[Literal["agent", "critics", END]]:
    messages = state["messages"]
    if state.get("commit_status"):
        return Command(update={"messages": messages + [HumanMessage("Done.")]}, goto=END)
    elif state.get("test_cases") and not state.get("critique"):
        return Command(update={"messages": messages + [HumanMessage("To critic...")]}, goto="critics")
    elif state.get("critique") and "invalid" in state["critique"].lower():
        return Command(update={"messages": messages + [HumanMessage("Regenerating tests.")], "test_cases": None, "critique": None}, goto="agent")
    return Command(update={"messages": messages + [HumanMessage("Agent working...")]}, goto="agent")

# Build the graph
workflow = StateGraph(TestCaseState)
workflow.add_node("agent", agent_node)
workflow.add_node("critics", critics_node)
workflow.add_node("supervisor", supervisor_node)
workflow.add_edge(START, "supervisor")
graph = workflow.compile()
